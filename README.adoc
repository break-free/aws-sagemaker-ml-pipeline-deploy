= Deploy and manage Machine Learning pipelines with Terraform using Amazon SageMaker
:toc:
:imagesdir: images

This repository contains Infrastructure as Code (IaC) to create and manage AWS infrastructure for a Machine Learning pipeline with SageMaker and Step Functions. Further it contains sample code for a Docker image to train and serve according to custom models on SageMaker. 

image::architecture-diagram.png[jpg]

=== Fedora Kinoite `build_sagemaker_toolbox.sh` script

This script is provided as is to allow Linux users to install the required tools, `terraform` and AWS CLI, into a local container. This keeps your immutable filesystem clean!

=== Deploy AWS Infrastructure with Terraform

The `terraform/infrastructure/terraform.tfvars` has been updated with a new project name (`breakfree`) and instance types amended to cheapest available for machine learning (`ml.c3.medium`). Also, the region has been updated to `us-east-1`.
 
Afterwards follow the steps below to deploy the infrastructure with Terraform. Note for the `AWS_PROFILE` refer to https://docs.aws.amazon.com/sdk-for-php/v3/developer-guide/guide_credentials_profiles.html[Using the AWS credentials file and credential Profiles] for guidance on multiple profiles.

```bash
$ export AWS_PROFILE=<your_aws_cli_profile_name>
$ cd terraform/infrastructure
$ terraform init
$ terraform plan
$ terraform apply
```

Check the output and make sure the planned resources appear correctly and confirm with ‘yes’ in the apply stage if everything is correct. Once successfully applied, record the output of the Terraform in the Terminal and get the URL for your ECR repository just created via Terraform. Note that both S3 buckets' names are also displayed and are used when destroying the resources later in this README.


=== Push your Docker Image to ECR

For the ML pipeline and SageMaker to train and provision an endpoint for inference, you need to provide a Docker image and store it in ECR. In the folder "sagemaker_byo" you will find an example, which relies on this repository https://github.com/aws/amazon-sagemaker-examples/tree/master/advanced_functionality/scikit_bring_your_own. If you already have applied the AWS infrastructure from the Terraform part, you can just push the Docker image as described below. Once your Docker image is developed, you can take the following actions and push it to ECR (adapt the ECR URL according to your output URL from the previous step):

```bash
$ cd src/container
$ export AWS_PROFILE=<your_aws_cli_profile_name> #If already done at the step above and profile still active, skip this step
$ aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin <account_number>.dkr.ecr.us-east-1.amazonaws.com
$ docker build -t ml-training .
$ docker tag ml-training:latest <account_number>.dkr.ecr.eu-west-1.amazonaws.com/<ecr_repository_name>:latest
$ docker push <account_number>.dkr.ecr.eu-west-1.amazonaws.com/<ecr_repository_name>
```

Or, if you prefer, use Podman (this may be easier for Windows users:)


   ```bash
   podman build --format docker -t ml-training . # be sure to include the docker format else this command won't work
   # Connect to the ECR, store its login credentials, and hand that over to Podman:
   aws ecr get-login-password --region us-east-1 | podman login --username AWS --password-stdin <account-number>.dkr.ecr.us-east-1.amazonaws.com/<repo-name>
   # Push your local image:
   podman push ml-training 428916778237.dkr.ecr.us-east-1.amazonaws.com/breakfree-ml-pipeline
   ```

=== Run the ML pipeline

In order to train and run the ML pipeline, go to Step Functions and start the execution. You can check progress of SageMaker also in the Training Jobs section of SageMaker and once the SageMaker Endpoint is created you can also check your SageMaker Endpoint. After running the State Machine in Step Functions successfully, you will see the SageMaker Endpoint being created in the AWS Console in the SageMaker Endpoints section. Make sure to wait for the Status to change to “InService”.

=== Invoke your endpoint

In order to invoke your endpoint (in this example for the iris dataset), you can use the following Python script with boto3 (Python SDK) to invoke your endpoint, for example from a Amazon SageMaker notebook.

```bash
$ cd src/invocation_script
$ chmod 0755 boto3_invoke.py  ## As needed
$ aws sagemaker list-endpoints 
$ ./boto3_invoke.py -e < _sagemaker-endpoint-name-from-previous-command_ >
```

=== Cleanup

In order to clean up, you can destroy the infrastructure created by Terraform with the command “terraform destroy”. But you will need to delete the data and files in the S3 buckets first. Further, the SageMaker Endpoint (or multiple SageMaker Endpoints if run multiple times) created via Step Functions is not managed via Terraform, but rather deployed when running the ML pipeline with Step Functions. Therefore, make sure you delete the SageMaker Endpoints created via the Step Function ML pipeline as well to avoid unnecessary costs.

==== Steps:

- Destroy the data in each of the created S3 buckets. Note that the buckets' names are outputted as part of the `terraform apply` when creating the infrastructure. Also note that bucket versioning should *not* be enabled.

```bash
$ aws s3 rm s3://< _bucket_training_data_name_ > --recursive
$ aws aws s3 rm s3://< _bucket_output_models_name_ > --recursive
```

- Destroy all container images in ECR.

```bash
$ aws ecr list-images --repository-name breakfree-ml-pipeline
$ aws ecr batch-delete-image --repository-name breakfree-ml-pipeline --image-ids imageDigest=< _image_digest_from_previous_command_ > [ imagedDigest=< _other_image_digests_from_previous_command_ > ]
```

- Destroy the infrastructure created via Terraform

```bash
$ cd terraform/infrastructure
$ terraform destroy
```

- Delete the SageMaker Endpoints, Endpoint Configuration and Models created via the Step Function in the AWS Console or via the AWS CLI.

```bash
$ aws sagemaker list-endpoints
$ aws sagemaker delete-endpoint --endpoint-name < _endpoint_name_ >
$ aws sagemaker list-endpoint-configs
$ aws sagemaker delete-endpoint-config --endpoint-config-name < _endpoint_config_name_ >
$ aws sagemaker list-models
$ aws sagemaker delete-model --model-name < _model_name_ >
```
